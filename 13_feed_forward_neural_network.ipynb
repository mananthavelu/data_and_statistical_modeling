{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssXOzxic3CFw"
      },
      "source": [
        "# Import the necessary libraries, dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qu8-lqRWaIuA"
      },
      "outputs": [],
      "source": [
        "# Buiding a NN model\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchsummary\n",
            "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
            "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
            "Installing collected packages: torchsummary\n",
            "Successfully installed torchsummary-1.5.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "incomplete input (320155085.py, line 35)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 35\u001b[1;36m\u001b[0m\n\u001b[1;33m    with torch.no_grad():\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "# 1. Data Preparation\n",
        "# Simple neural network to predict the delivery time using distance\n",
        "distances = torch.tensor([[1.0], [2.0], [3.0], [4.0]], dtype=torch.float32)# 4 examples with single feature\n",
        "\n",
        "# Delivery times in minutes\n",
        "times = torch.tensor([[6.96], [12.11],[16.77],[22.21]], dtype=torch.float32)# Truth labels with signle output\n",
        "\n",
        "# 2. Modelling - Architecture, hyper parameters\n",
        "# Streamlined version of the connected layer, 1 input, 1 output\n",
        "model = nn.Sequential(nn.Linear(1,1))\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_function = nn.MSELoss() # Uses to tune the parameters\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # How to optimize the parameters\n",
        "\n",
        "# 3. Training\n",
        "for epoch in range(500):\n",
        "    # 0. Reset the optimizer\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1. Make predictions\n",
        "    outputs = model(distances)\n",
        "\n",
        "    # 2. Calculate the loss\n",
        "    loss = loss_function(outputs, times)\n",
        "\n",
        "    # 3. Calculate adjustments\n",
        "    loss.backward()\n",
        "\n",
        "    # 4. Update the model parameters\n",
        "    optimizer.step()\n",
        "\n",
        "# Inference\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_distance = torch.tensor([[25.0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[5.0703]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([1.8239], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for param in model.parameters():\n",
        "    print(param)  # Prints the tensor values of each parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSJbLVcwbgn5",
        "outputId": "a6492e8a-7b2c-4f4a-d71a-86627f08497c"
      },
      "outputs": [],
      "source": [
        "# Doanloading the training ata from open datasets\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "4YfL9ob5NH-h",
        "outputId": "60990143-afad-42cf-ffa5-f0a04243c0ae"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# Access the first image with its label\n",
        "image, label = training_data[4]\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.imshow(image.squeeze(), cmap = 'gray')\n",
        "plt.show()\n",
        "print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GI-ZV4jDbzXZ"
      },
      "outputs": [],
      "source": [
        "# Doanload the test data from open datasets\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTBJN480cDC5",
        "outputId": "ab019f82-2ada-4f80-d4e3-2b6c3222624e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "# Define the batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7LVfZLRcIXP",
        "outputId": "8c8f42ed-4a7b-433f-82e2-1475b6a6ded3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: {device}\n"
          ]
        }
      ],
      "source": [
        "# Creating models\n",
        "# Accelerator usage\n",
        "device = torch.accelerator.current_accelerator().type\\\n",
        "if torch.accelerator.is_available() else \"cpu\"\n",
        "\n",
        "print(\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UZpEtA8KZDV"
      },
      "source": [
        "# Define the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_hd9ab-OdDu",
        "outputId": "da9ec2dd-1144-4b71-e644-6a9f8477f582"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewhhP2OkZKoA"
      },
      "source": [
        "**Optimizing the model parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XclxuANBPTkn"
      },
      "outputs": [],
      "source": [
        "loss_function = nn.CrossEntropyLoss()# Define the loss function which will drive the optimization\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = 1e-3)#the optimizer which takes the loss information and updates the weight\n",
        "# Loss function -> Gradients -> Weights adjustments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXrkIOBSKnKD"
      },
      "source": [
        "# Define the 'Train' method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1fb5emICXuY1"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_function, optimizer):\n",
        "  size = len(dataloader.dataset)# Size of the training dataset\n",
        "  model.train()# Train the model\n",
        "  for batch, (X,y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    prediction = model(X)\n",
        "    loss = loss_function(prediction, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()# Calculate the gradients and attach it to .grad attribute for each parameter\n",
        "    optimizer.step()# Optimizer has access to params # Update the weights of the model\n",
        "    optimizer.zero_grad()# Reset the gradients to 0 so the gradients from prev. iteration dont accumulate\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch+1)* len(X)\n",
        "      print(f\"loss:{loss:>7f} [{current:>5d}/{size:.>5d}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE-Tw2F-KwWb"
      },
      "source": [
        "# Define the 'Test' method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xofU7jia2cLL"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_function):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_of_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      predictions = model(X)\n",
        "      test_loss += loss_function(predictions, y).item()\n",
        "      correct += (predictions.argmax(1) == y). type(torch.float).sum().item()\n",
        "  test_loss /= num_of_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100* correct):>0.1}%, Avg loss: {test_loss:>8f} \\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S02P_ZEEK0lM"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_0hLuVf-jhK",
        "outputId": "a2eb1510-6a2d-4614-acc5-26668c1232cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 \n",
            "---------"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "loss:2.306156 [   64/60000]\n",
            "loss:2.294207 [ 6464/60000]\n",
            "loss:2.271687 [12864/60000]\n",
            "loss:2.265670 [19264/60000]\n",
            "loss:2.252181 [25664/60000]\n",
            "loss:2.227238 [32064/60000]\n",
            "loss:2.232957 [38464/60000]\n",
            "loss:2.203803 [44864/60000]\n",
            "loss:2.196992 [51264/60000]\n",
            "loss:2.174772 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 4e+01%, Avg loss: 2.165463 \n",
            "\n",
            "Epoch 2 \n",
            "---------\n",
            "loss:2.176948 [   64/60000]\n",
            "loss:2.171444 [ 6464/60000]\n",
            "loss:2.109101 [12864/60000]\n",
            "loss:2.123826 [19264/60000]\n",
            "loss:2.080888 [25664/60000]\n",
            "loss:2.025473 [32064/60000]\n",
            "loss:2.042127 [38464/60000]\n",
            "loss:1.970429 [44864/60000]\n",
            "loss:1.970824 [51264/60000]\n",
            "loss:1.906743 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 6e+01%, Avg loss: 1.905416 \n",
            "\n",
            "Epoch 3 \n",
            "---------\n",
            "loss:1.937409 [   64/60000]\n",
            "loss:1.915263 [ 6464/60000]\n",
            "loss:1.791272 [12864/60000]\n",
            "loss:1.826277 [19264/60000]\n",
            "loss:1.723569 [25664/60000]\n",
            "loss:1.675596 [32064/60000]\n",
            "loss:1.682092 [38464/60000]\n",
            "loss:1.592382 [44864/60000]\n",
            "loss:1.609545 [51264/60000]\n",
            "loss:1.509313 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 6e+01%, Avg loss: 1.528501 \n",
            "\n",
            "Epoch 4 \n",
            "---------\n",
            "loss:1.594684 [   64/60000]\n",
            "loss:1.567597 [ 6464/60000]\n",
            "loss:1.407161 [12864/60000]\n",
            "loss:1.473608 [19264/60000]\n",
            "loss:1.360917 [25664/60000]\n",
            "loss:1.353788 [32064/60000]\n",
            "loss:1.360566 [38464/60000]\n",
            "loss:1.292632 [44864/60000]\n",
            "loss:1.324674 [51264/60000]\n",
            "loss:1.232528 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 6e+01%, Avg loss: 1.254337 \n",
            "\n",
            "Epoch 5 \n",
            "---------\n",
            "loss:1.329715 [   64/60000]\n",
            "loss:1.319887 [ 6464/60000]\n",
            "loss:1.143541 [12864/60000]\n",
            "loss:1.245286 [19264/60000]\n",
            "loss:1.125534 [25664/60000]\n",
            "loss:1.146541 [32064/60000]\n",
            "loss:1.164747 [38464/60000]\n",
            "loss:1.108397 [44864/60000]\n",
            "loss:1.146258 [51264/60000]\n",
            "loss:1.068789 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 6e+01%, Avg loss: 1.085422 \n",
            "\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n---------\")\n",
        "  train(train_dataloader, model, loss_function, optimizer)\n",
        "  test(test_dataloader, model, loss_function)\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4YwNYXe_K2j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q9FiSUbK6Vn"
      },
      "source": [
        "# Save the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4cW09neK8Za",
        "outputId": "8793de3c-6396-4fd4-9538-092a0e26a1b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved PyTorch model state to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch model state to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMOML2r8LhV4"
      },
      "source": [
        "# Load the Pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUDrxq-eLA0y",
        "outputId": "fb8d7992-be01-4b02-d4a3-7ec63cf09814"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only = True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceoR4w_4LkAi"
      },
      "source": [
        "# Make the predictions on the new data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6SDXgT0LSgS",
        "outputId": "822d0d90-cdc5-4885-b224-b0dc0aafb55e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6hMpjZMLrGD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
