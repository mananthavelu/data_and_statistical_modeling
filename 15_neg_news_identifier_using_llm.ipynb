{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073bf8f9",
   "metadata": {},
   "source": [
    "#### Use LLM to output the contextual information present in a text\n",
    "\n",
    "Requirement:\n",
    "* Interact with OpenAI model using API\n",
    "* Use LLM for understanding the context in a text\n",
    "* Use LLM to solve one possible use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Interact with OpenAI API\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Securly save the API key locally\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484bfa6a",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a helper function to receive the response\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # for minimal randomness\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a1d076ce",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, I am here to assist you. How can I help you today?'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample response\n",
    "get_completion(\"Are you available to assist?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e458c7b9",
   "metadata": {},
   "source": [
    "#### Use LLM to understand the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1b32b57a",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question that is : Is this text content has any indication of any crime or confiction?.     If yes, respond with 'yes'. If no, respond with 'no'    If yes who has committed?, if no, just leave empty space\n",
      "    If yes, is it a person or organization involved in it?.\n",
      "    Simply provide these responses separeted by comma     using the text that is delimited by triple backticks      text: ```\n",
      "Traveling to have a business meeting takes the fun out of the trip.Especially if you have to prepare a presentation. I would suggest holding the business plan meetings here then take a trip without any formal business meetings.I would even try and get some honest opinions on whether a trip is even desired or necessary. As far as the business meetings, I think it would be more productive to tryand stimulate discussions across the different groups about what is working and what is not.Too often the presenter speaks and the others are quiet just waiting for their turn. The meetings might be better if held in a round table discussion format.My suggestion for where to go is Austin. Play golf and rent a ski boat and jet ski's. Flying somewhere takes too much time. John Mcthy is involved in fraud investigation```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LLMs understand the context well - which is one of very useful application of it.\n",
    "# In this below example, we will try to demonstrate\n",
    "# The below email content was taken from huggingface/enron - dataset as an example\n",
    "\n",
    "text_content = \"\"\"\n",
    "Traveling to have a business meeting takes the fun out of the trip.\\\n",
    "Especially if you have to prepare a presentation. I would suggest holding \\\n",
    "the business plan meetings here then take a trip without any formal business meetings.\\\n",
    "I would even try and get some honest opinions on whether a trip is even desired or \\\n",
    "necessary. As far as the business meetings, I think it would be more productive to try\\\n",
    "and stimulate discussions across the different groups about what is working and what is not.\\\n",
    "Too often the presenter speaks and the others are quiet just waiting for their turn. \\\n",
    "The meetings might be better if held in a round table discussion format.\\\n",
    "My suggestion for where to go is Austin. Play golf and rent a ski boat and jet ski's. \\\n",
    "Flying somewhere takes too much time. John Mcthy is involved in fraud investigation\\\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"Is this text content has any indication of any crime or confiction?. \\\n",
    "    If yes, respond with 'yes'. If no, respond with 'no'\\\n",
    "    If yes who has committed?, if no, just leave empty space\n",
    "    If yes, is it a person or organization involved in it?.\n",
    "    Simply provide these responses separeted by comma\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Answer the question that is : {question} \\\n",
    "    using the text that is delimited by triple backticks  \\\n",
    "    text: ```{text_content}```\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c883dcbd",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes, John Mcthy, person'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c5b27",
   "metadata": {},
   "source": [
    "#### Interact with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f0d4a269",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use langchain library for the use case\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# To control the randomness and creativity of the generated text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "57bda7d8",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the prompt as a string with inputs closed with {}\n",
    "prompt = \"\"\"Answer the question that is : {question} using the text\\\n",
    "      that is delimited by triple backticks  text: ```{text_content}```\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cac2cb16",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question', 'text_content']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Template takes two parameters as input\n",
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dff3954f",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "news_text_context = prompt_template.format_messages(\n",
    "                    question=question,\n",
    "                    text_content=text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bd789f9f",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "yes, John Mcthy, person\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "news_text_context_output = chat(news_text_context)\n",
    "print(news_text_context_output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36536e79",
   "metadata": {},
   "source": [
    "#### Extracting the outputs in needed format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c2e0ec49",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9dea24b4",
   "metadata": {
    "height": 353,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_schema = ResponseSchema(name=\"result\",\n",
    "                             description=\"Is this text content has any \\\n",
    "                                indication of any crime or confiction?. \\\n",
    "                                If yes, respond with 'yes'. If no, respond \\\n",
    "                                with 'no'\")\n",
    "name_schema = ResponseSchema(name=\"name\",\n",
    "                              description=\"If yes who has committed?,\\\n",
    "                              if no, just leave empty space\")\n",
    "entity_type_schema = ResponseSchema(name=\"entity\",\n",
    "                                    description=\"If yes, is it a person or organization\\\n",
    "                                    involved in it?\")\n",
    "\n",
    "response_schemas = [result_schema, \n",
    "                    name_schema,\n",
    "                    entity_type_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e1ba8",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1eb176c5",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"result\": string  // Is this text content has any                                 indication of any crime or confiction?.                                 If yes, respond with 'yes'. If no, respond                                 with 'no'\n",
      "\t\"name\": string  // If yes who has committed?,                              if no, just leave empty space\n",
      "\t\"entity\": string  // If yes, is it a person or organization                                    involved in it?\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "082947fc",
   "metadata": {
    "height": 370,
    "tags": []
   },
   "outputs": [],
   "source": [
    "template_alternate = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "result: Is this text content has any \\\n",
    "    indication of any crime or confiction?. \\\n",
    "    If yes, respond with 'yes'. If no, respond \\\n",
    "    with 'no'\n",
    "\n",
    "name: If yes who has committed?,\\\n",
    "    if no, just leave empty space.\n",
    "\n",
    "entity: If yes, is it a person or organization\\\n",
    "        involved in it?\n",
    "\n",
    "text: {text_content}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=template_alternate)\n",
    "\n",
    "messages = prompt.format_messages(text_content=text_content, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1f1537a7",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "result: Is this text content has any     indication of any crime or confiction?.     If yes, respond with 'yes'. If no, respond     with 'no'\n",
      "\n",
      "name: If yes who has committed?,    if no, just leave empty space.\n",
      "\n",
      "entity: If yes, is it a person or organization        involved in it?\n",
      "\n",
      "text: \n",
      "Traveling to have a business meeting takes the fun out of the trip.Especially if you have to prepare a presentation. I would suggest holding the business plan meetings here then take a trip without any formal business meetings.I would even try and get some honest opinions on whether a trip is even desired or necessary. As far as the business meetings, I think it would be more productive to tryand stimulate discussions across the different groups about what is working and what is not.Too often the presenter speaks and the others are quiet just waiting for their turn. The meetings might be better if held in a round table discussion format.My suggestion for where to go is Austin. Play golf and rent a ski boat and jet ski's. Flying somewhere takes too much time. John Mcthy is involved in fraud investigation\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"result\": string  // Is this text content has any                                 indication of any crime or confiction?.                                 If yes, respond with 'yes'. If no, respond                                 with 'no'\n",
      "\t\"name\": string  // If yes who has committed?,                              if no, just leave empty space\n",
      "\t\"entity\": string  // If yes, is it a person or organization                                    involved in it?\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7b663657",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"result\": \"yes\",\n",
      "\t\"name\": \"John Mcthy\",\n",
      "\t\"entity\": \"person\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "904f1c25",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict = output_parser.parse(response.content)\n",
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b647a",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 'yes', 'name': 'John Mcthy', 'entity': 'person'}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the output for correctness\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099b6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Mcthy'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output_dict['name']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
